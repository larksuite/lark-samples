// langchain.js - LangChain with Lark OpenAPI MCP Demo
// langchain.js - LangChain ä¸ Lark OpenAPI MCP é€‚é…å™¨æ¼”ç¤º

// If you need more information about LangChain, please refer to https://js.langchain.com/docs/tutorials/
// å¦‚æœä½ éœ€è¦æ›´å¤šå…³äº LangChain çš„ä¿¡æ¯ï¼Œè¯·å‚è€ƒ https://js.langchain.com/docs/tutorials/

import { MultiServerMCPClient } from "@langchain/mcp-adapters";
import { ChatOpenAI } from "@langchain/openai";
import { createReactAgent } from "@langchain/langgraph/prebuilt";
import { systemPrompt, userPrompt } from "./prompt.js";

import dotenv from "dotenv";

// Load environment variables from .env file
// ä» .env æ–‡ä»¶åŠ è½½ç¯å¢ƒå˜é‡
dotenv.config();

// Validate required environment variables
// éªŒè¯å¿…éœ€çš„ç¯å¢ƒå˜é‡
if (!process.env.OPENAI_API_KEY || !process.env.OPENAI_MODEL) {
  throw new Error(
    "OPENAI_API_KEY, OPENAI_MODEL is required | OPENAI_API_KEY å’Œ OPENAI_MODEL æ˜¯å¿…éœ€çš„"
  );
}

// Create OpenAI model with support for multiple providers
// åˆ›å»ºæ”¯æŒå¤šä¸ªæä¾›å•†çš„ OpenAI æ¨¡å‹
const model = new ChatOpenAI({
  configuration: {
    baseURL: process.env.OPENAI_BASE_URL,
    apiKey: process.env.OPENAI_API_KEY,
    defaultHeaders: {
      // Adapt to different AI services | é€‚é…ä¸åŒçš„ AI æœåŠ¡
      "api-key": process.env.OPENAI_API_KEY, // Azure OpenAI | Azure OpenAI
      "x-api-key": process.env.OPENAI_API_KEY, // Some providers | æŸäº›æä¾›å•†
      Authorization: `Bearer ${process.env.OPENAI_API_KEY}`, // Standard format | æ ‡å‡†æ ¼å¼
    },
  },
  apiKey: process.env.OPENAI_API_KEY,
  modelName: process.env.OPENAI_MODEL,
});

/**
 * Create and configure Lark MCP client using MultiServerMCPClient
 * ä½¿ç”¨ MultiServerMCPClient åˆ›å»ºå’Œé…ç½® Lark MCP å®¢æˆ·ç«¯
 *
 * @returns {Promise<MultiServerMCPClient>} Configured MCP client | é…ç½®å¥½çš„ MCP å®¢æˆ·ç«¯
 */
async function createLarkMCPClient() {
  return new MultiServerMCPClient({
    mcpServers: {
      "lark-mcp": {
        transport: "stdio", // Use stdio for process communication | ä½¿ç”¨ stdio è¿›è¡Œè¿›ç¨‹é€šä¿¡
        command: "npx", // Use Node.js package runner | ä½¿ç”¨ Node.js åŒ…è¿è¡Œå™¨
        args: [
          "-y",
          "@larksuiteoapi/lark-mcp",
          "mcp",
          "--token-mode",
          "tenant_access_token",
          // ä½ å¯ä»¥è‡ªå®šä¹‰å¼€å¯çš„ Tools æˆ–è€… Presets / You can custom enable tools or presets here
          // '-t',
          // 'bitable.v1.app.create,bitable.v1.appTable.create',
        ],
        env: {
          // Lark app credentials for API access | ç”¨äº API è®¿é—®çš„é£ä¹¦/Larkåº”ç”¨å‡­è¯
          APP_ID: process.env.APP_ID,
          APP_SECRET: process.env.APP_SECRET,
          LARK_DOMAIN: process.env.LARK_DOMAIN, // Feishu/Lark request domain | é£ä¹¦/Lark API è¯·æ±‚åŸŸå
        },
      },
    },
  });
}

async function main() {
  const mcpClient = await createLarkMCPClient();
  const tools = await mcpClient.getTools();
  const agent = createReactAgent({ llm: model, tools });

  console.log("ğŸš€ invoke agent");
  try {
    const response = await agent.invoke({
      messages: [
        { role: "system", content: systemPrompt },
        { role: "user", content: userPrompt },
      ],
    });
    console.log(response);
  } catch (error) {
    console.error("Error during agent execution:", error);
  }

  await mcpClient.close();
}

main();

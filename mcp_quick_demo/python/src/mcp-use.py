# mcp-use.py - mcp-use implementation demo
# mcp-use.py - mcp-use å®ç°æ¼”ç¤º


# If you need more information about mcp-use, please refer to https://mcp-use.com/
# å¦‚æœä½ éœ€è¦æ›´å¤šå…³äº mcp-use çš„ä¿¡æ¯ï¼Œè¯·å‚è€ƒ https://mcp-use.com/

import asyncio
import os
from langchain_openai import ChatOpenAI
from mcp_use import MCPAgent, MCPClient
import dotenv
from prompt import user_prompt, system_prompt

# Load environment variables from .env file
# ä» .env æ–‡ä»¶åŠ è½½ç¯å¢ƒå˜é‡
dotenv.load_dotenv()

# Get configuration from environment variables
# ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
base_url = os.getenv("OPENAI_BASE_URL")
api_key = os.getenv("OPENAI_API_KEY")
model_name = os.getenv("OPENAI_MODEL")

# Validate required environment variables
# éªŒè¯å¿…éœ€çš„ç¯å¢ƒå˜é‡
if not api_key or not model_name:
    raise ValueError(
        "OPENAI_API_KEY, OPENAI_MODEL is required | OPENAI_API_KEY å’Œ OPENAI_MODEL æ˜¯å¿…éœ€çš„"
    )

# Initialize OpenAI model with custom headers for different providers
# ä½¿ç”¨è‡ªå®šä¹‰æ ‡å¤´ä¸ºä¸åŒæä¾›å•†åˆå§‹åŒ– OpenAI æ¨¡å‹
model = ChatOpenAI(
    base_url=base_url,
    model=model_name,
    api_key=api_key,
    default_headers={
        "Api-Key": api_key
    },  # Support for various API providers | æ”¯æŒå„ç§ API æä¾›å•†
    max_tokens=1000,
    verbose=True,
)


def create_lark_mcp_client():
    """
    Create and configure Lark MCP client
    åˆ›å»ºå’Œé…ç½® Lark MCP å®¢æˆ·ç«¯

    Returns:
        MCPClient: Configured MCP client instance
        MCPClient: é…ç½®å¥½çš„ MCP å®¢æˆ·ç«¯å®ä¾‹
    """
    config = {
        "mcpServers": {
            "lark-mcp": {
                "command": "npx",  # Use Node.js package runner | ä½¿ç”¨ Node.js åŒ…è¿è¡Œå™¨
                "args": [
                    "-y",
                    "@larksuiteoapi/lark-mcp",
                    "mcp",
                    "--token-mode",
                    "tenant_access_token",
                    # ä½ å¯ä»¥è‡ªå®šä¹‰å¼€å¯çš„ Tools æˆ–è€… Presets / You can custom enable tools or presets here
                    # '-t',
                    # 'bitable.v1.app.create,bitable.v1.appTable.create',
                ],
                "env": {
                    # Lark app credentials for API access | ç”¨äº API è®¿é—®çš„é£ä¹¦/Larkåº”ç”¨å‡­è¯
                    "APP_ID": os.getenv("APP_ID"),
                    "APP_SECRET": os.getenv("APP_SECRET"),
                    "LARK_DOMAIN": os.getenv(
                        "LARK_DOMAIN"
                    ),  #  Feishu/Lark request domain | é£ä¹¦/Lark API è¯·æ±‚åŸŸå
                },
            }
        }
    }
    return MCPClient.from_dict(config)


async def main():
    """
    Main async function to run the MCP agent demo
    è¿è¡Œ MCP Agentæ¼”ç¤ºçš„ä¸»å¼‚æ­¥å‡½æ•°
    """
    # Create MCP client and agent
    # åˆ›å»º MCP å®¢æˆ·ç«¯å’ŒAgent
    client = create_lark_mcp_client()
    agent = MCPAgent(
        llm=model,
        client=client,
        max_steps=10,
        system_prompt=system_prompt,
    )  # Limit execution steps | é™åˆ¶æ‰§è¡Œæ­¥éª¤

    print("ğŸš€ è°ƒç”¨Agent | Invoking agent")
    result = await agent.run(
        query=user_prompt,
    )
    print("âœ… Agentå“åº” | Agent response")
    print(f"\nç»“æœ | Result: {result}")


if __name__ == "__main__":
    try:
        # Run the main async function
        # è¿è¡Œä¸»å¼‚æ­¥å‡½æ•°
        asyncio.run(main())
    except KeyboardInterrupt:
        print("ğŸ›‘ Exiting...")
        exit(0)

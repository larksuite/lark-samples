# MCP Quick Demo - Python Implementation

# MCP å¿«é€Ÿæ¼”ç¤º - Python å®ç°

## Overview | æ¦‚è¿°

This project provides two different Python implementations for integrating with the Model Context Protocol (MCP). It demonstrates how to connect to a Lark MCP server and interact with Feishu documents using AI agents with both custom MCP clients and LangChain adapters.

æœ¬é¡¹ç›®æä¾›äº†ä¸¤ç§ä¸åŒçš„ Python å®ç°æ¥é›†æˆæ¨¡å‹ä¸Šä¸‹æ–‡åè®® (MCP)ã€‚å®ƒæ¼”ç¤ºäº†å¦‚ä½•è¿æ¥åˆ° Lark MCP æœåŠ¡å™¨ï¼Œå¹¶ä½¿ç”¨è‡ªå®šä¹‰ MCP å®¢æˆ·ç«¯å’Œ LangChain é€‚é…å™¨é€šè¿‡ AI Agent ä¸é£ä¹¦/Lark æ–‡æ¡£äº¤äº’ã€‚

## Project Files | é¡¹ç›®æ–‡ä»¶

### Core Demos | æ ¸å¿ƒæ¼”ç¤º

1. **`mcp-use.py`** - Direct MCP implementation using mcp-use library
   ä½¿ç”¨ mcp-use åº“çš„ç›´æ¥ MCP å®ç°

2. **`langchain-demo.py`** - LangChain-based implementation with MCP adapters
   åŸºäº LangChain çš„ MCP é€‚é…å™¨å®ç°

### Supporting Files | æ”¯æŒæ–‡ä»¶

- **`prompt.py`** - Shared prompt definitions | å…±äº«æç¤ºè¯å®šä¹‰
- **`pyproject.toml`** - Project dependencies and configuration | é¡¹ç›®ä¾èµ–å’Œé…ç½®

## Prerequisites | å‰ç½®è¦æ±‚

- Python 3.13 or higher | Python 3.13 æˆ–æ›´é«˜ç‰ˆæœ¬
- Node.js (for Lark MCP server) | Node.jsï¼ˆç”¨äº Lark MCP æœåŠ¡å™¨ï¼‰
- OpenAI API key | OpenAI API å¯†é’¥
- Lark app credentials | é£ä¹¦/Lark åº”ç”¨å‡­è¯

## Installation | å®‰è£…

1.  **Clone the repository | å…‹éš†ä»“åº“**

    ```bash
    git clone https://github.com/larksuite/lark-samples
    cd mcp_quick_demo/python
    ```

2.  **Set up Python environment | è®¾ç½® Python ç¯å¢ƒ**

    Using uv (recommended) | ä½¿ç”¨ uvï¼ˆæ¨èï¼‰ï¼š

    ```bash
    uv sync
    ```

3.  **Set up environment variables | è®¾ç½®ç¯å¢ƒå˜é‡**

    Create a `.env` file in the project root:
    åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º `.env` æ–‡ä»¶ï¼š

   ```env
   OPENAI_API_KEY=your_openai_api_key
   OPENAI_MODEL=gpt-4o
   APP_ID=your_lark_app_id
   APP_SECRET=your_lark_app_secret
   OPENAI_BASE_URL=https://api.openai.com/v1
   ```

4.  **Feishu/Lark Application Configuration | é£ä¹¦/Lark/Lark åº”ç”¨é…ç½®**

    Configure in Feishu/Lark Open Platform Developer Console:
    åœ¨ é£ä¹¦/Lark/Lark å¼€æ”¾å¹³å°å¼€å‘è€…åå°ä¸­é…ç½®ï¼š

    1. **Create an app | åˆ›å»ºåº”ç”¨**
    2. **Bot Configuration | æœºå™¨äººé…ç½®**

       - Enable bot functionality | å¯ç”¨æœºå™¨äººåŠŸèƒ½

    3. **Permission Configuration | æƒé™é…ç½®**

       - Add necessary API permissions, like docx:docx | æ·»åŠ å¿…è¦çš„ API æƒé™ï¼Œä¾‹å¦‚ docx:docx

    4. **Publish the app | å‘å¸ƒåº”ç”¨**

## Usage | ä½¿ç”¨æ–¹æ³•

### Option 1: MCP-Use Implementation | é€‰é¡¹ 1ï¼šMCP-Use å®ç°

Run the MCP-Use implementation:
è¿è¡Œ MCP-Use å®ç°ï¼š

```bash
uv run src/mcp-use.py
```

This demo uses the `mcp-use` library for MCP integration.
æ­¤æ¼”ç¤ºä½¿ç”¨ `mcp-use` åº“è¿›è¡Œ MCP é›†æˆã€‚

### Option 2: LangChain Implementation | é€‰é¡¹ 2ï¼šLangChain å®ç°

Run the LangChain-based implementation:
è¿è¡ŒåŸºäº LangChain çš„å®ç°ï¼š

```bash
uv run src/langchain-demo.py
```

This demo leverages LangChain's MCP adapters for a more framework-integrated approach.
æ­¤æ¼”ç¤ºåˆ©ç”¨ LangChain çš„ MCP é€‚é…å™¨è¿›è¡Œæ›´å¤šæ¡†æ¶é›†æˆçš„æ–¹æ³•ã€‚

### Customizing Prompts | è‡ªå®šä¹‰æç¤ºè¯

Edit the `prompt.py` file to modify the user query:
ç¼–è¾‘ `prompt.py` æ–‡ä»¶æ¥ä¿®æ”¹ç”¨æˆ·æŸ¥è¯¢ï¼š

```python
user_prompt = "Your custom query here"
```

### è‡ªå®šä¹‰å·¥å…· / Customizing Tools

å¦‚æœæ‚¨éœ€è¦è‡ªå®šä¹‰å¯ç”¨çš„å·¥å…·é›†ï¼Œå¯ä»¥ç›´æ¥ä¿®æ”¹ `src/mcp-use.py` æˆ– `src/langchain-demo.py` æ–‡ä»¶ã€‚åœ¨è¯¥æ–‡ä»¶ä¸­ï¼Œæ‚¨å¯ä»¥æ‰¾åˆ°è¢«æ³¨é‡Šæ‰çš„å·¥å…·é…ç½®ä»£ç ï¼Œå–æ¶ˆæ³¨é‡Šå¹¶æ ¹æ®æ‚¨çš„éœ€æ±‚è¿›è¡Œä¿®æ”¹å³å¯ã€‚

If you need to customize the enabled toolset, you can directly modify the `src/mcp-use.py` or `src/langchain-demo.py` file. In this file, you will find commented-out tool configuration code. Uncomment it and modify it according to your needs.

[Learn More](https://open.feishu.cn/document/uAjLw4CM/ukTMukTMukTM/mcp_integration/advanced-configuration#74738783)

## Project Structure | é¡¹ç›®ç»“æ„

```
python/
â”œâ”€â”€ src/mcp-use.py              # Direct MCP implementation | ç›´æ¥ MCP å®ç°
â”œâ”€â”€ src/langchain-demo.py       # LangChain MCP implementation | LangChain MCP å®ç°
â”œâ”€â”€ src/prompt.py               # Shared prompts | å…±äº«æç¤ºè¯
â”œâ”€â”€ pyproject.toml          # Project configuration | é¡¹ç›®é…ç½®
â”œâ”€â”€ uv.lock                 # Dependency lock file | ä¾èµ–é”å®šæ–‡ä»¶
â””â”€â”€ .env                    # Environment variables | ç¯å¢ƒå˜é‡
```

## Troubleshooting | æ•…éšœæ’é™¤

### Common Issues | å¸¸è§é—®é¢˜

1. **Missing Dependencies | ç¼ºå¤±ä¾èµ–**

   ```
   ModuleNotFoundError: No module named 'mcp_use'
   ```

   Solution: Run `uv sync`
   è§£å†³æ–¹æ¡ˆï¼šè¿è¡Œ `uv sync`

2. **Environment Variables Not Set | ç¯å¢ƒå˜é‡æœªè®¾ç½®**

   ```
   ValueError: OPENAI_API_KEY, OPENAI_MODEL is required
   ```

   Solution: Create a `.env` file with all required variables
   è§£å†³æ–¹æ¡ˆï¼šåˆ›å»ºåŒ…å«æ‰€æœ‰å¿…éœ€å˜é‡çš„ `.env` æ–‡ä»¶

3. **MCP Server Connection Failed | MCP æœåŠ¡å™¨è¿æ¥å¤±è´¥**
   ```
   ConnectionError: Failed to connect to MCP server
   ```
   Solution: Ensure Node.js is installed and Lark MCP server is accessible
   è§£å†³æ–¹æ¡ˆï¼šç¡®ä¿å·²å®‰è£… Node.js ä¸” Lark MCP æœåŠ¡å™¨å¯è®¿é—®

## ğŸ“š Resources | èµ„æº

### Documentation | æ–‡æ¡£

- [LangChain MCP Adapters](https://github.com/langchain-ai/langchain-mcp-adapters)
- [LangChain](https://python.langchain.com/docs/)
- [MCP Use](https://mcp-use.com)
- [Model Context Protocol](https://modelcontextprotocol.io/introduction)
- [OpenAI API Documentation](https://platform.openai.com/docs)
- [Feishu Open Platform](https://open.feishu.cn/)
- [Lark Developer](https://open.larksuite.com/)
- [Lark OpenAPI MCP](https://github.com/larksuite/lark-openapi-mcp)

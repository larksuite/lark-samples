// langchain.js - LangChain with Lark OpenAPI MCP Demo
// langchain.js - LangChain ä¸ Lark OpenAPI MCP é€‚é…å™¨æ¼”ç¤º

// If you need more information about LangChain, please refer to https://js.langchain.com/docs/tutorials/
// å¦‚æœä½ éœ€è¦æ›´å¤šå…³äº LangChain çš„ä¿¡æ¯ï¼Œè¯·å‚è€ƒ https://js.langchain.com/docs/tutorials/

import { MultiServerMCPClient } from "@langchain/mcp-adapters";
import { ChatOpenAI } from "@langchain/openai";
import { createAgent } from "langchain";
import { systemPrompt, userPrompt } from "./prompt.js";
import * as Lark from "@larksuiteoapi/node-sdk";

import dotenv from "dotenv";

// Load environment variables from .env file
// ä» .env æ–‡ä»¶åŠ è½½ç¯å¢ƒå˜é‡
dotenv.config();

// Validate required environment variables
// éªŒè¯å¿…éœ€çš„ç¯å¢ƒå˜é‡
if (!process.env.OPENAI_API_KEY || !process.env.OPENAI_MODEL) {
  throw new Error(
    "OPENAI_API_KEY, OPENAI_MODEL is required | OPENAI_API_KEY å’Œ OPENAI_MODEL æ˜¯å¿…éœ€çš„"
  );
}

// Create OpenAI model with support for multiple providers
// åˆ›å»ºæ”¯æŒå¤šä¸ªæä¾›å•†çš„ OpenAI æ¨¡å‹
const model = new ChatOpenAI({
  configuration: {
    baseURL: process.env.OPENAI_BASE_URL,
    apiKey: process.env.OPENAI_API_KEY,
    defaultHeaders: {
      // Adapt to different AI services | é€‚é…ä¸åŒçš„ AI æœåŠ¡
      "api-key": process.env.OPENAI_API_KEY, // Azure OpenAI | Azure OpenAI
      "x-api-key": process.env.OPENAI_API_KEY, // Some providers | æŸäº›æä¾›å•†
      Authorization: `Bearer ${process.env.OPENAI_API_KEY}`, // Standard format | æ ‡å‡†æ ¼å¼
    },
  },
  apiKey: process.env.OPENAI_API_KEY,
  modelName: process.env.OPENAI_MODEL,
});

/**
 * Create and configure Lark MCP client using MultiServerMCPClient
 * ä½¿ç”¨ MultiServerMCPClient åˆ›å»ºå’Œé…ç½® Lark MCP å®¢æˆ·ç«¯
 *
 * @returns {Promise<MultiServerMCPClient>} Configured MCP client | é…ç½®å¥½çš„ MCP å®¢æˆ·ç«¯
 */
async function createLarkMCPClient() {
  // Initialize Lark Client
  // åˆå§‹åŒ–é£ä¹¦/Lark å®¢æˆ·ç«¯
  const client = new Lark.Client({
    appId: process.env.APP_ID,
    appSecret: process.env.APP_SECRET,
  });

  // Get Tenant Access Token
  // è·å– Tenant Access Token
  const tenantAccessToken = await client.tokenManager.getTenantAccessToken();

  // Get MCP URL and allowed tools from environment variables
  // ä»ç¯å¢ƒå˜é‡è·å– MCP URL å’Œå…è®¸ä½¿ç”¨çš„å·¥å…·
  const mcpUrl = process.env.MCP_URL || "https://mcp.feishu.cn/mcp";
  const allowedTools =
    process.env.LARK_MCP_ALLOWED_TOOLS || "get-comments,fetch-doc";
    
  // Create MultiServerMCPClient with HTTP transport
  // åˆ›å»ºå¸¦æœ‰ HTTP ä¼ è¾“çš„ MultiServerMCPClient
  return new MultiServerMCPClient({
    mcpServers: {
      "lark-mcp": {
        transport: "http",
        url: mcpUrl,
        headers: {
          // Pass allowed tools and TAT via headers
          // é€šè¿‡è¯·æ±‚å¤´ä¼ é€’å…è®¸çš„å·¥å…·å’Œ TAT
          "X-Lark-MCP-Allowed-Tools": allowedTools,
          "X-Lark-MCP-TAT": tenantAccessToken,
        },
      },
    },
  });
}

async function main() {
  const mcpClient = await createLarkMCPClient();
  const tools = await mcpClient.getTools();
  const agent = createAgent({ model, tools });

  console.log("ğŸš€ è°ƒç”¨ Agent | Invoke agent");
  try {
    const response = await agent.invoke({
      messages: [
        { role: "system", content: systemPrompt },
        { role: "user", content: userPrompt },
      ],
    });
    console.log(response);
  } catch (error) {
    console.error("Error during agent execution:", error);
  }

  await mcpClient.close();
}

main();

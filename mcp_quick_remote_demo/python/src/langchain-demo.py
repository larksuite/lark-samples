# langchain-demo.py - LangChain MCP integration with Lark OpenAPI MCP demo
# langchain-demo.py - LangChain MCP é›†æˆ Lark OpenAPI MCP æ¼”ç¤º

# If you need more information about LangChain, please refer to https://python.langchain.com/docs/tutorials/
# å¦‚æœä½ éœ€è¦æ›´å¤šå…³äº LangChain çš„ä¿¡æ¯ï¼Œè¯·å‚è€ƒ https://python.langchain.com/docs/tutorials/

import asyncio
import os
import lark_oapi as lark
from lark_oapi.api.auth.v3 import *
from langchain_mcp_adapters.client import MultiServerMCPClient
from langchain_core.tools import BaseTool
from langchain_core.messages import HumanMessage
from langchain_core.utils.function_calling import convert_to_openai_tool
from langchain_openai import ChatOpenAI
from langchain_mcp_adapters.tools import load_mcp_tools
from langchain.agents import create_agent
import dotenv
from prompt import user_prompt

# Load environment variables from .env file
# ä» .env æ–‡ä»¶åŠ è½½ç¯å¢ƒå˜é‡
dotenv.load_dotenv()

# Get configuration from environment variables
# ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
base_url = os.getenv(
    "OPENAI_BASE_URL"
)  # Custom OpenAI API base URL | è‡ªå®šä¹‰ OpenAI API åŸºç¡€ URL
api_key = os.getenv("OPENAI_API_KEY")  # OpenAI API key | OpenAI API å¯†é’¥
model_name = os.getenv("OPENAI_MODEL")  # Model name to use | è¦ä½¿ç”¨çš„æ¨¡å‹åç§°

# Validate required environment variables
# éªŒè¯å¿…éœ€çš„ç¯å¢ƒå˜é‡
if not api_key or not model_name:
    raise ValueError(
        "OPENAI_API_KEY, OPENAI_MODEL is required | OPENAI_API_KEY å’Œ OPENAI_MODEL æ˜¯å¿…éœ€çš„"
    )

# Initialize OpenAI model with custom configuration
# ä½¿ç”¨è‡ªå®šä¹‰é…ç½®åˆå§‹åŒ– OpenAI æ¨¡å‹
model = ChatOpenAI(
    base_url=base_url,  # Custom base URL for different providers | ä¸åŒæä¾›å•†çš„è‡ªå®šä¹‰åŸºç¡€ URL
    model=model_name,  # Specified model name | æŒ‡å®šçš„æ¨¡å‹åç§°
    api_key=api_key,  # API authentication key | API è®¤è¯å¯†é’¥
    default_headers={
        "Api-Key": api_key
    },  # Additional headers for compatibility | å…¼å®¹æ€§çš„é¢å¤–æ ‡å¤´
    max_tokens=1000,  # Maximum tokens in response | å“åº”ä¸­çš„æœ€å¤§ä»¤ç‰Œæ•°
    verbose=True,  # Enable verbose logging | å¯ç”¨è¯¦ç»†æ—¥å¿—
)


def get_tat():
    """
    Get Tenant Access Token from Lark/Feishu
    ä»é£ä¹¦è·å– Tenant Access Token
    """
    app_id = os.getenv("APP_ID")
    app_secret = os.getenv("APP_SECRET")

    if not app_id or not app_secret:
        raise ValueError("APP_ID and APP_SECRET are required")

    client = (
        lark.Client.builder()
        .app_id(app_id)
        .app_secret(app_secret)
        .domain(os.getenv("LARK_DOMAIN", "https://open.feishu.cn"))
        .build()
    )

    req = (
        InternalTenantAccessTokenRequest.builder()
        .request_body(
            InternalTenantAccessTokenRequestBody.builder()
            .app_id(app_id)
            .app_secret(app_secret)
            .build()
        )
        .build()
    )

    resp = client.auth.v3.tenant_access_token.internal(req)

    if not resp.success():
        raise Exception(f"Failed to get tenant access token: {resp.msg}")

    import json

    data = json.loads(resp.raw.content)
    return data.get("tenant_access_token")


def create_lark_mcp_client(tenant_access_token):
    """
    Create and configure Lark MCP client using MultiServerMCPClient
    ä½¿ç”¨ MultiServerMCPClient åˆ›å»ºå’Œé…ç½® Lark MCP å®¢æˆ·ç«¯

    Returns:
        MultiServerMCPClient: Configured MCP client instance for Lark integration
        MultiServerMCPClient: ç”¨äºé£ä¹¦/Larké›†æˆçš„é…ç½®å¥½çš„ MCP å®¢æˆ·ç«¯å®ä¾‹
    """
    # Get MCP URL and allowed tools from environment variables
    # ä»ç¯å¢ƒå˜é‡è·å– MCP URL å’Œå…è®¸ä½¿ç”¨çš„å·¥å…·
    mcp_url = os.getenv("MCP_URL", "https://mcp.feishu.cn/mcp")
    allowed_tools = os.getenv("LARK_MCP_ALLOWED_TOOLS", "get-comments,fetch-doc")

    # Create MultiServerMCPClient with HTTP transport
    # åˆ›å»ºå¸¦æœ‰ HTTP ä¼ è¾“çš„ MultiServerMCPClient
    return MultiServerMCPClient(
        {
            "lark-mcp": {  # Server identifier | æœåŠ¡å™¨æ ‡è¯†ç¬¦
                "transport": "http",
                "url": mcp_url,
                "headers": {
                    # Pass allowed tools and TAT via headers
                    # é€šè¿‡è¯·æ±‚å¤´ä¼ é€’å…è®¸çš„å·¥å…·å’Œ TAT
                    "X-Lark-MCP-Allowed-Tools": allowed_tools,
                    "X-Lark-MCP-TAT": tenant_access_token,
                },
            }
        }
    )


async def main():
    """
    Main async function to run the LangChain MCP agent demo
    è¿è¡Œ LangChain MCP Agentæ¼”ç¤ºçš„ä¸»å¼‚æ­¥å‡½æ•°
    """
    # Get Tenant Access Token
    tat = get_tat()

    # Create MCP client instance
    # åˆ›å»º MCP å®¢æˆ·ç«¯å®ä¾‹
    client = create_lark_mcp_client(tat)

    # Use async context manager to manage MCP session
    # ä½¿ç”¨å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨æ¥ç®¡ç† MCP ä¼šè¯
    async with client.session("lark-mcp") as session:
        # Load MCP tools from the session
        # ä»ä¼šè¯ä¸­åŠ è½½ MCP å·¥å…·
        tools = await load_mcp_tools(session)

        # Create Agent with model and loaded tools
        # ä½¿ç”¨æ¨¡å‹å’ŒåŠ è½½çš„å·¥å…·åˆ›å»º Agent
        agent = create_agent(model=model, tools=tools)

        print("ğŸš€ è°ƒç”¨Agent | Invoking agent")

        # Execute agent with user prompt and get response
        # ä½¿ç”¨ç”¨æˆ·æç¤ºæ‰§è¡ŒAgentå¹¶è·å–å“åº”
        response = await agent.ainvoke({"messages": user_prompt})

        print("âœ… Agentå“åº” | Agent response")
        print(f"\nç»“æœ | Result: {response}")


if __name__ == "__main__":
    try:
        # Run the main async function
        # è¿è¡Œä¸»å¼‚æ­¥å‡½æ•°
        asyncio.run(main())
    except KeyboardInterrupt:
        print("ğŸ›‘ Exiting...")
